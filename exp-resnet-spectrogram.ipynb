{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bedfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import timm\n",
    "\n",
    "import transforms.eft as Eft\n",
    "import datasets.radioml_dataset as RadiomlDT\n",
    "from datasets.transformed_dataset import TransformedDataset\n",
    "from utils import plot_confusion_matrix\n",
    "from models.radio_rec_model import RadioRecNetwork\n",
    "from models.resnet import create_resnet_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf18dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.signal_file_dataset as sfds\n",
    "\n",
    "root = \"/home/zwlin/data/radio\"\n",
    "sig_file_set = sfds.SignalFileSet(root, 'bin')\n",
    "sig_file_set.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_file_conf = sfds.SignalFileConfig()\n",
    "sig_file_conf.fs = 100000 # 100K Hz sample rate\n",
    "sig_file_conf.seg_len = 500 # 500 ms\n",
    "sig_file_conf.seg_shift = 500 # 500 ms, no overlap\n",
    "sig_file_conf.max_num = 1000\n",
    "sig_file_conf.is_complex = True\n",
    "sig_file_conf.energy_threshold = 6\n",
    "\n",
    "sig_dataset = sfds.SignalDataSet(sig_file_set, sig_file_conf)\n",
    "sig_dataset.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59902f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = sig_dataset.class_list\n",
    "num_classes = len(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c538ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat but plot andom sampling of the data\n",
    "from datasets.visualize import IQVisualizer\n",
    "\n",
    "example_dataloader = DataLoader(\n",
    "    dataset=sig_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=10,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "visualizer = IQVisualizer(\n",
    "    data_loader = example_dataloader,\n",
    "    visualize_target_transform = lambda target: [label_list[int(index)] for index in target]\n",
    ")\n",
    "\n",
    "for figure in iter(visualizer):\n",
    "    figure.set_size_inches(14, 9)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms.transforms import Compose\n",
    "from transforms.spectrogram_transform import SpectrogramConfig, Spectrogram\n",
    "\n",
    "interleave_to_complex = Eft.InterleaveToComplex()\n",
    "\n",
    "spectrogram_config = SpectrogramConfig()\n",
    "spectrogram_config.nperseg = 256\n",
    "spectrogram_config.noverlap = 128\n",
    "spectrogram_config.nfft = 256\n",
    "spectrogram_config.window = 'hann'\n",
    "spectrogram_config.return_onesided = False\n",
    "spectrogram_config.mode = 'magnitude'\n",
    "\n",
    "spectorgram_transform = Spectrogram(spectrogram_config)\n",
    "\n",
    "ds = TransformedDataset(sig_dataset, transform = Compose([interleave_to_complex, spectorgram_transform]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = len(ds)\n",
    "num_train = math.floor(0.8 * num_total)\n",
    "num_val = math.floor(0.1 * num_total)\n",
    "num_test = num_total - num_train - num_val\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(ds, [num_train, num_val, num_test],\n",
    "                                                                         generator = torch.Generator().manual_seed(42))\n",
    "idx = np.random.randint(len(train_dataset))\n",
    "data, label = train_dataset[idx]\n",
    "channels = data.shape[0]\n",
    "print(\"Dataset length: {}\".format(len(ds)))\n",
    "print(\"Data shape: {}\".format(data.shape))\n",
    "print(f\"Channels: {channels}\")\n",
    "print(\"Label Index: {}\".format(label))\n",
    "print(\"Label Class: {}\".format(label_list[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----\n",
    "# ### Format Dataset for Training\n",
    "# Next, the datasets are then wrapped as `DataLoaders` to prepare for training.\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_resnet_2d(name = 'resnet18', pretrained = False, num_classes = num_classes, in_chans = channels)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e65aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Config\n",
    "learning_rate=0.002\n",
    "epochs = 50\n",
    "\n",
    "radiorec_model = RadioRecNetwork(model, learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47dcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----\n",
    "# ### Train the Model\n",
    "# To train the model, we first create a `ModelCheckpoint` to monitor the validation loss over time and save the best model as we go. The network is then instantiated and passed into a `Trainer` to kick off training.\n",
    "import os\n",
    "checkpoint_dir=f'exp/radioml2018-iq-all-{rediorec_model.learning_rate}-v3/checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    print(f'mkdir: {checkpoint_dir}')\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup checkpoint callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename='{epoch}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=epochs, callbacks=checkpoint_callback, devices=1, accelerator=\"gpu\"\n",
    ")\n",
    "\n",
    "trainer.fit(radiorec_model, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the model is trained, the checkpoint's weights are loaded into the model and the model is put into evaluation mode. The validation set is looped through, inferring results for each example and saving the predictions and the labels. Finally, the labels and predictions are passed into our confusion matrix plotting function to view the results and also passed into the `sklearn.metrics.classification_report` method to print metrics of interest.\n",
    "# checkpoint_filename = checkpoint_callback.best_model_path\n",
    "checkpoint_filename = 'exp/radioml2018-iq-all-0.002-v3/checkpoints/epoch=26-val_loss=0.13.ckpt'\n",
    "\n",
    "# Load best checkpoint\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "checkpoint = torch.load(\n",
    "    checkpoint_filename, map_location=lambda storage, loc: storage\n",
    ")\n",
    "\n",
    "model = create_resnet(name = 'resnet18', pretrained = False, num_classes = num_classes, in_chans = channels)\n",
    "test_model = RadioRecNetwork(model, learning_rate = learning_rate)\n",
    "test_model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "test_model = test_model.to(device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707eae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Evaluate the val set\n",
    "\n",
    "# Infer results over validation set\n",
    "num_val_examples = len(val_dataset)\n",
    "y_raw_preds = np.empty((num_val_examples, num_classes))\n",
    "y_preds = np.zeros((num_val_examples,))\n",
    "y_true = np.zeros((num_val_examples,))\n",
    "\n",
    "for i in tqdm(range(0, num_val_examples)):\n",
    "    # Retrieve data\n",
    "    idx = i  # Use index if evaluating over full dataset\n",
    "    data, label = val_dataset[idx]\n",
    "    # Infer\n",
    "    data = torch.from_numpy(np.expand_dims(data, 0)).float().to(device)\n",
    "    pred_tmp = test_model.predict(data)\n",
    "    pred_tmp = pred_tmp.cpu().numpy() if torch.cuda.is_available() else pred_tmp\n",
    "    # Argmax\n",
    "    y_preds[i] = np.argmax(pred_tmp)\n",
    "    # Store label\n",
    "    y_true[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944da79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.sum(np.asarray(y_preds) == np.asarray(y_true)) / len(y_true)\n",
    "plot_confusion_matrix(\n",
    "    y_true,\n",
    "    y_preds,\n",
    "    classes = label_list,\n",
    "    normalize = True,\n",
    "    title=\"Validation Set Modulations Confusion Matrix\\nTotal Accuracy: {:.2f}%\".format(\n",
    "        acc * 100\n",
    "    ),\n",
    "    text=False,\n",
    "    rotate_x_text=90,\n",
    "    figsize=(16, 9),\n",
    ")\n",
    "plt.savefig(f\"{checkpoint_dir}/val_result.png\")\n",
    "\n",
    "print(\"Val set classification report:\")\n",
    "print(classification_report(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65034f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----\n",
    "# ### Evaluate the test set\n",
    "\n",
    "# Infer results over validation set\n",
    "num_test_examples = len(test_dataset)\n",
    "y_raw_preds = np.empty((num_test_examples, num_classes))\n",
    "y_preds = np.zeros((num_test_examples,))\n",
    "y_true = np.zeros((num_test_examples,))\n",
    "\n",
    "for i in tqdm(range(0, num_test_examples)):\n",
    "    # Retrieve data\n",
    "    idx = i  # Use index if evaluating over full dataset\n",
    "    data, label = test_dataset[idx]\n",
    "    # Infer\n",
    "    data = torch.from_numpy(np.expand_dims(data, 0)).float().to(device)\n",
    "    pred_tmp = test_model.predict(data)\n",
    "    pred_tmp = pred_tmp.cpu().numpy() if torch.cuda.is_available() else pred_tmp\n",
    "    # Argmax\n",
    "    y_preds[i] = np.argmax(pred_tmp)\n",
    "    # Store label\n",
    "    y_true[i] = label\n",
    "\n",
    "acc = np.sum(np.asarray(y_preds) == np.asarray(y_true)) / len(y_true)\n",
    "plot_confusion_matrix(\n",
    "    y_true,\n",
    "    y_preds,\n",
    "    classes = label_list,\n",
    "    normalize = True,\n",
    "    title=\"Test Set Modulations Confusion Matrix\\nTotal Accuracy: {:.2f}%\".format(\n",
    "        acc * 100\n",
    "    ),\n",
    "    text=False,\n",
    "    rotate_x_text=90,\n",
    "    figsize=(16, 9),\n",
    ")\n",
    "plt.savefig(f\"{checkpoint_dir}/test_result.png\")\n",
    "\n",
    "print(\"Test set classification report:\")\n",
    "print(classification_report(y_true, y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
